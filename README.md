# Sentiment Analysis of Self-Driving Car Tweets

> End-to-end NLP project comparing **Bag-of-Words (TF-IDF)**, **MPQA subjectivity lexicon**, a **Hybrid (BoW+MPQA)** approach, and **Dependency-Triple features** for classifying tweet sentiment about autonomous vehicles.

![Python](https://img.shields.io/badge/Python-3.9%2B-3776AB)
![scikit-learn](https://img.shields.io/badge/scikit--learn-ML-orange)
![NLTK](https://img.shields.io/badge/NLTK-NLP-4CAF50)
![Status](https://img.shields.io/badge/Status-Academic%20Project-blue)
![License](https://img.shields.io/badge/License-MIT-lightgrey)

---

## ğŸ” Overview

This repository implements and evaluates four sentiment-classification strategies on tweet data about **self-driving cars**:

1. **BoW (TF-IDF)**: tokenize â†’ POS-filter (**NOUN/ADJ/VERB**) â†’ lemmatize â†’ TF-IDF n-grams â†’ Linear SVM.
2. **MPQA Lexicon Features**: aggregate positive/negative/neutral counts per tweet as dense features.
3. **Hybrid (BoW + MPQA)**: augment the text with polarity hints (e.g., appending `positive`/`negative` tokens) before TF-IDF.
4. **Dependency Triples**: parse tweets, extract `(head, relation, dependent)` tuples, and hash as features.

**Labels:** original 5-point (plus â€œnot relevantâ€) annotations collapsed to **four classes**:
`-1 = not relevant`, `1 = negative`, `2 = neutral`, `3 = positive`.

---

## ğŸ§° Tech Stack

- Python 3.9+
- scikit-learn for vectorization & classic ML (LinearSVC / Naive Bayes)
- NLTK for tokenization, POS tagging, and lemmatization
- (Optional) spaCy for dependency parsing (or NLTK + JPype if using MaltParser)
- tqdm, pandas, numpy for utilities/IO

---

## ğŸ—‚ï¸ Repository Structure

    .
    â”œâ”€ data/
    â”‚  â””â”€ raw/                     # Put the CSV here (self-driving car tweets)
    â”œâ”€ mpqa/
    â”‚  â””â”€ subjectivity_lexicon/    # MPQA word lists (pos/neg/neutral)
    â”œâ”€ src/
    â”‚  â”œâ”€ data.py                  # loading, label mapping, cleaning
    â”‚  â”œâ”€ features_bow.py          # POS-filter, lemmatize, TF-IDF
    â”‚  â”œâ”€ features_mpqa.py         # MPQA counters + token hints
    â”‚  â”œâ”€ features_dep.py          # dependency triples
    â”‚  â”œâ”€ models.py                # train/eval loops (SVM, NB)
    â”‚  â”œâ”€ baselines.py             # VADER, Naive Bayes baselines
    â”‚  â””â”€ utils.py                 # seeds, metrics, logging
    â”œâ”€ notebooks/
    â”‚  â””â”€ exploration.ipynb        # optional EDA
    â”œâ”€ README.md
    â””â”€ requirements.txt

> **Data:** Download the â€œSelf-Driving Car Sentimentâ€ CSV (CrowdFlower/Data.World) and place it under `data/raw/`. Ensure your loader maps labels to `{-1, 1, 2, 3}`.

---

## ğŸ“¦ Installation

Create and activate a virtual environment, then install dependencies:

    python -m venv .venv
    # Windows: .venv\Scripts\activate
    # macOS/Linux:
    source .venv/bin/activate

    pip install -U pip
    pip install -r requirements.txt

**Suggested `requirements.txt`:**

    pandas
    numpy
    scikit-learn
    nltk
    tqdm
    matplotlib
    # Choose ONE parsing path below:
    spacy
    # and then: python -m spacy download en_core_web_sm
    # OR use MaltParser via NLTK (requires Java + JPype):
    jpype1

First run: download NLTK resources:

    python -c "import nltk; [nltk.download(p) for p in ['punkt','averaged_perceptron_tagger','wordnet','omw-1.4']]"

---

## ğŸš€ Quickstart (Experiments)

Train and evaluate different experiments:

    # BoW (unigrams)
    python -m src.models --exp bow --ngrams 1 1

    # BoW (uni+bi)
    python -m src.models --exp bow --ngrams 1 2

    # BoW (uni+bi+tri)
    python -m src.models --exp bow --ngrams 1 3

    # MPQA-only features
    python -m src.models --exp mpqa

    # Hybrid (BoW + MPQA hints)
    python -m src.models --exp hybrid --ngrams 1 1

    # Dependency triples
    python -m src.models --exp dep

    # Baselines
    python -m src.bas


Each command prints accuracy, macro-F1, and a concise classification report on a stratified validation split.

---

## ğŸ“Š Expected Results (Guide)

| Model                            | Typical Outcome* |
|----------------------------------|-----------------:|
| Hybrid (BoW + MPQA)             | strong baseline  |
| BoW (unigrams / uni+bi)         | strong baseline  |
| Dependency triples              | moderate         |
| MPQA-only                       | modest           |
| VADER / Naive Bayes (baselines) | baseline         |

\* Reproduce locally; results depend on seed, preprocessing choices, and class mapping. Report **macro-F1** alongside accuracy due to class imbalance.

---

## ğŸ§  Implementation Notes

- **Preprocessing:** lowercase; normalize URLs/mentions; optional emoji handling.  
- **POS filter:** keep **NOUN/ADJ/VERB**; remove stopwords; **lemmatize** with WordNet.  
- **Vectorization:** `TfidfVectorizer` with tuned `min_df`, `max_df`, `ngram_range`; consider `sublinear_tf=True`.  
- **Classifier:** `LinearSVC` with a small grid over `C`; compare against MultinomialNB for sanity.  
- **MPQA features:** per-tweet counts (+ optional polarity token appending for Hybrid).  
- **Dependency features:** spaCy `en_core_web_sm` or MaltParser; hash triples like `"head_REL_dep"`.

---

## ğŸ“ˆ Evaluation & Reproducibility

- **Split:** Stratified 80/20 or K-fold CV; fix a **random seed**.  
- **Metrics:** Accuracy (headline) and **macro-F1**; include per-class precision/recall/F1.  
- **Artifacts:** Save model + vectorizer to `artifacts/model.joblib` and `artifacts/vectorizer.joblib`.  
- **Versions:** Lock with `python -m pip freeze > artifacts/requirements.lock`.

Enable a detailed report:

    python -m src.models --exp hybrid --ngrams 1 2 --report

---

## ğŸ§ª Tests (Optional)

    tests/
    â”œâ”€ test_data.py
    â”œâ”€ test_features_bow.py
    â”œâ”€ test_features_mpqa.py
    â”œâ”€ test_features_dep.py
    â””â”€ test_models.py

Run tests:

    pytest -q

---

## ğŸ”§ Troubleshooting

- **spaCy model not found:**  
  Install: `python -m spacy download en_core_web_sm`
- **MaltParser route:**  
  Ensure Java is installed; add `jpype1`; configure parser path for NLTKâ€™s interface.
- **CSV encoding errors:**  
  Load with `encoding="utf-8"` and `errors="ignore"` as a fallback.

---

## ğŸ“š Acknowledgments

- MPQA Subjectivity Lexicon  
- VADER Sentiment  
- spaCy & NLTK teams  
- CrowdFlower/Data.World dataset curators

---

## ğŸ“ Citation

    @misc{selfdriving-tweet-sentiment,
      title  = {Sentiment Analysis of Self-Driving Car Tweets},
      author = {Your Name},
      year   = {2025},
      note   = {Course Project}
    }

---

## ğŸ“„ License

Released under the **MIT License**. See `LICENSE` for details.

